{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local registration with ICP\n",
    "\n",
    "    In the RGBD folder we have the first 400 images from one of the datasets from: (http://redwood-data.org/indoor_lidar_rgbd/download.html)\n",
    "\n",
    "\n",
    "    If you want to display directly in jupyter notebook replace the **draw_registrations** with this:\n",
    "\n",
    "```python\n",
    "from open3d import JVisualizer\n",
    "\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "        source_temp = copy.deepcopy(source)\n",
    "        target_temp = copy.deepcopy(target)\n",
    "        if(recolor):\n",
    "            source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "            target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "        if(transformation is not None):\n",
    "            source_temp.transform(transformation)\n",
    "        visualizer = JVisualizer()\n",
    "        visualizer.add_geometry(source_temp)\n",
    "        visualizer.add_geometry(target_temp)\n",
    "        visualizer.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "        \n",
    "# Helper function to draw registrations (reccomended)\n",
    "def draw_registrations(source, target, transformation = None, recolor = False):\n",
    "        source_temp = copy.deepcopy(source)\n",
    "        target_temp = copy.deepcopy(target)\n",
    "        if(recolor):\n",
    "            source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "            target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "        if(transformation is not None):\n",
    "            source_temp.transform(transformation)\n",
    "        o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "# sum of squared differences\n",
    "def ssd(source, target):\n",
    "    return np.sum(np.square(source - target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating pointclouds from image data\n",
    "Now we are going to try to create our own pointclouds from rgb and depth images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in images. We have images 000000 - 0000400\n",
    "color_raw0 = o3d.io.read_image(\"RGBD/color/000000.jpg\")\n",
    "depth_raw0 = o3d.io.read_image(\"RGBD/depth/000000.png\")\n",
    "\n",
    "color_raw1 = o3d.io.read_image(\"RGBD/color/000005.jpg\")\n",
    "depth_raw1 = o3d.io.read_image(\"RGBD/depth/000005.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pointclouds from rgb + depth images.\n",
    "\n",
    "If you set *convert_rgb_to_intensity = False* you will retain the colors from the rgb image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd_image0 = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    color_raw0, \n",
    "    depth_raw0, \n",
    "    convert_rgb_to_intensity = True)\n",
    "\n",
    "rgbd_image1 = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    color_raw1, \n",
    "    depth_raw1, \n",
    "    convert_rgb_to_intensity = True)\n",
    "\n",
    "#show images\n",
    "fig= plt.figure(figsize=(15,15))\n",
    "plt.subplot(221)\n",
    "plt.title('Redwood grayscale0 image')\n",
    "plt.imshow(rgbd_image0.color, cmap='gray')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.title('Redwood depth0 image')\n",
    "plt.imshow(rgbd_image0.depth)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.title('Redwood grayscale1 image')\n",
    "plt.imshow(rgbd_image1.color, cmap='gray')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.title('Redwood depth1 image')\n",
    "plt.imshow(rgbd_image1.depth)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images to Pointcloud\n",
    "Now we create point clouds from the rgbd images we just created.\n",
    "\n",
    "\n",
    "Here we use **PinholeCameraIntrinsicParameters.PrimeSenseDefault** as default camera parameter. \n",
    "\n",
    "It has image resolution 640x480, focal length (fx, fy) = (525.0, 525.0), and optical center (cx, cy) = (319.5, 239.5). \n",
    "\n",
    "An identity matrix is used as the default extrinsic parameter. pcd.transform applies an up-down flip transformation on the point cloud for better visualization purpose.\n",
    "\n",
    "\n",
    "If it becomes too slow you can downsample the pointcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source pointcloud\n",
    "camera = o3d.camera.PinholeCameraIntrinsic(\n",
    "        o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)\n",
    "\n",
    "source = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "    rgbd_image0, camera)\n",
    "\n",
    "# Target pointcloud\n",
    "target = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "    rgbd_image1, camera)\n",
    "\n",
    "# Flip it, otherwise the pointcloud will be upside down\n",
    "source.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "target.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "# Draw\n",
    "draw_registrations(source, target, recolor=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of pointclouds\n",
    "\n",
    "Before we can run ICP we evaluate our source and target pointclouds. This gives us a measure to see if we need a better initial transformation or not.\n",
    "\n",
    "[The function evaluate_registration calculates two main metrics. fitness measures the overlapping area (# of inlier correspondences / # of points in target). Higher the better. inlier_rmse measures the RMSE of all inlier correspondences. Lower the better.](http://www.open3d.org/docs/latest/tutorial/Basic/icp_registration.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "threshold = 0.02\n",
    "trans_init = np.asarray([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "#Evaluate registration\n",
    "print(\"Initial alignment\")\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(source, target, threshold, trans_init)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICP\n",
    "\n",
    "Now try to call icp with your point clouds and your initial transformation.\n",
    "\n",
    "Initially we use:\n",
    "```Python\n",
    "point_to_plane =  o3d.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "icp_result = o3d.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    point_to_plane)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# ICP code here\n",
    "###\n",
    "\n",
    "point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "##############\n",
    "# Downsample #\n",
    "##############\n",
    "voxel_size = 0.05\n",
    "# 1 Downsample both point clouds\n",
    "source = source.voxel_down_sample(voxel_size=voxel_size)\n",
    "target = target.voxel_down_sample(voxel_size=voxel_size)\n",
    "# 2 Estimate surface normals of pointclouds\n",
    "source.estimate_normals()\n",
    "target.estimate_normals()\n",
    "\n",
    "icp_result = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    point_to_plane)\n",
    "    \n",
    "draw_registrations(source, target, icp_result.transformation, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exersices\n",
    "\n",
    "### A)\n",
    "If you increase the amount of steps from the original image so from i.e. 000000-000001 to 00000-000300 what happens?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in images. We have images 000000 - 0000400\n",
    "color_raw0 = o3d.io.read_image(\"RGBD/color/000001.jpg\")\n",
    "depth_raw0 = o3d.io.read_image(\"RGBD/depth/000001.png\")\n",
    "\n",
    "color_raw1 = o3d.io.read_image(\"RGBD/color/000301.jpg\")\n",
    "depth_raw1 = o3d.io.read_image(\"RGBD/depth/000301.png\")\n",
    "\n",
    "#####################\n",
    "# Recombine to RGBD #\n",
    "#####################\n",
    "rgbd_image0 = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    color_raw0, \n",
    "    depth_raw0, \n",
    "    convert_rgb_to_intensity = True)\n",
    "\n",
    "rgbd_image1 = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    color_raw1, \n",
    "    depth_raw1, \n",
    "    convert_rgb_to_intensity = True)\n",
    "\n",
    "# Create camera model\n",
    "camera = o3d.camera.PinholeCameraIntrinsic(\n",
    "        o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)\n",
    "\n",
    "# Source pointcloud\n",
    "source = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "    rgbd_image0, camera)\n",
    "\n",
    "# Target pointcloud\n",
    "target = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "    rgbd_image1, camera)\n",
    "\n",
    "# Flip it, otherwise the pointcloud will be upside down\n",
    "source.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "target.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "##############\n",
    "# Downsample #\n",
    "##############\n",
    "voxel_size = 0.01\n",
    "# 1 Downsample both point clouds\n",
    "source.voxel_down_sample(voxel_size=voxel_size)\n",
    "target.voxel_down_sample(voxel_size=voxel_size)\n",
    "# 2 Estimate surface normals of pointclouds\n",
    "source.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                        max_nn=30),fast_normal_computation=True)\n",
    "target.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                        max_nn=30),fast_normal_computation=True)\n",
    "\n",
    "###########\n",
    "# Fitness #\n",
    "###########\n",
    "\n",
    "# Parameters\n",
    "threshold = 0.02\n",
    "trans_init = np.asarray([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "#Evaluate registration\n",
    "print(\"Initial alignment\")\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(source, target, threshold, trans_init)\n",
    "print(evaluation)\n",
    "\n",
    "#######\n",
    "# ICP #\n",
    "#######\n",
    "\n",
    "point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "icp_result = o3d.pipelines.registration.registration_icp(\n",
    "    source,\n",
    "    target,\n",
    "    max_correspondence_distance=threshold,\n",
    "    init=trans_init, \n",
    "    estimation_method=point_to_plane\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_registrations(source, target, icp_result.transformation, recolor=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### B)\n",
    "Can you tweak the parameters *threshold* and *trans_init* to combat some of the ill effects that starts appearing?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Fitness #\n",
    "###########\n",
    "\n",
    "# Parameters\n",
    "threshold = 1.5 # Increased so we can detect the correct points\n",
    "trans_init = np.asarray([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "#Evaluate registration\n",
    "print(\"Initial alignment\")\n",
    "evaluation = o3d.pipelines.registration.evaluate_registration(source, target, threshold, trans_init)\n",
    "print(evaluation)\n",
    "\n",
    "#######\n",
    "# ICP #\n",
    "#######\n",
    "\n",
    "point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "icp_result = o3d.pipelines.registration.registration_icp(\n",
    "    source,\n",
    "    target,\n",
    "    max_correspondence_distance=threshold,\n",
    "    init=trans_init, \n",
    "    estimation_method=point_to_point\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_registrations(source, target, icp_result.transformation, recolor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### C)\n",
    "Again try to use \n",
    "```Python\n",
    "point_to_plane =  o3d.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "reg_p2p = o3d.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    point_to_plane)\n",
    "```\n",
    "\n",
    "This requires you to find the normals for each point cloud use:\n",
    "```python\n",
    "    source.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                            max_nn=30),fast_normal_computation=True)\n",
    "```\n",
    "Compare the resulting translations of the two methods is one better than the other?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "threshold = 1.5 # Increased so we can detect the correct points\n",
    "trans_init = np.asarray([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    source, target, threshold, trans_init,\n",
    "    point_to_plane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_registrations(source, target, reg_p2p.transformation, recolor=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### D)\n",
    "Extend this and try to see how much of the bedroom you can reconstruct from the rgb and depth images.\n",
    "you can extend a pointcloud by new = source + target remember to resample the point cloud some times so it does not get too large down_source = source.voxel_down_sample(voxel_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_pc(source, no, voxel_size=0.005):\n",
    "    # Read in images. We have images 000000 - 0000400\n",
    "    if no<10:\n",
    "        no = \"00000\"+str(no)\n",
    "        color_raw1 = o3d.io.read_image(\"RGBD/color/\"+no+\".jpg\")\n",
    "        depth_raw1 = o3d.io.read_image(\"RGBD/color/\"+no+\".jpg\")\n",
    "    elif 10<=no<100:\n",
    "        no = \"0000\"+str(no)\n",
    "        color_raw1 = o3d.io.read_image(\"RGBD/color/\"+no+\".jpg\")\n",
    "        depth_raw1 = o3d.io.read_image(\"RGBD/color/\"+no+\".jpg\")\n",
    "    elif 100<=no<1000:\n",
    "        no = \"000\"+str(no)\n",
    "        color_raw1 = o3d.io.read_image(\"RGBD/color/\"+no+\".jpg\")\n",
    "        depth_raw1 = o3d.io.read_image(\"RGBD/color/\"+no+\".jpg\")\n",
    "    else:\n",
    "        return source\n",
    "\n",
    "    #####################\n",
    "    # Recombine to RGBD #\n",
    "    #####################\n",
    "    rgbd_image1 = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        color_raw1, \n",
    "        depth_raw1, \n",
    "        convert_rgb_to_intensity = True)\n",
    "\n",
    "    # Create camera model\n",
    "    camera = o3d.camera.PinholeCameraIntrinsic(\n",
    "            o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)\n",
    "\n",
    "    # Target pointcloud\n",
    "    target = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "        rgbd_image1, camera)\n",
    "\n",
    "    # Flip it, otherwise the pointcloud will be upside down\n",
    "    target.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "    ##############\n",
    "    # Downsample #\n",
    "    ##############\n",
    "    # 1 Downsample both point clouds\n",
    "    #source = source.voxel_down_sample(voxel_size=voxel_size)\n",
    "    #target = target.voxel_down_sample(voxel_size=voxel_size)\n",
    "    # 2 Estimate surface normals of pointclouds\n",
    "    source.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                            max_nn=30),fast_normal_computation=True)\n",
    "    target.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                            max_nn=30),fast_normal_computation=True)\n",
    "\n",
    "    #######\n",
    "    # ICP #\n",
    "    #######\n",
    "    # Parameters\n",
    "    threshold = 0.02\n",
    "    trans_init = np.asarray([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "    #point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "    point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "    icp_result = o3d.pipelines.registration.registration_icp(\n",
    "        source,\n",
    "        target,\n",
    "        max_correspondence_distance=threshold,\n",
    "        init=trans_init, \n",
    "        estimation_method=point_to_plane\n",
    "        )\n",
    "    print(no, end=\"... \")\n",
    "    # Transform the source points to targets coordinates, and add target\n",
    "    new = source.transform(icp_result.transformation) + target #.voxel_down_sample(voxel_size=voxel_size)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_process(source, voxel_size=0.005):\n",
    "    \n",
    "    for i in range(1, 30):\n",
    "        # Read in images. We have images 000000 - 0000400\n",
    "        no = 0\n",
    "        if i<10:\n",
    "            no = \"00000\"+str(i)\n",
    "            color_raw1 = o3d.io.read_image(\"RGBD/color/\"+no+\".jpg\")\n",
    "            depth_raw1 = o3d.io.read_image(\"RGBD/color/\"+no+\".jpg\")\n",
    "        elif 10<=i<100:\n",
    "            no = \"0000\"+str(i)\n",
    "            color_raw1 = o3d.io.read_image(\"RGBD/color/\"+no+\".jpg\")\n",
    "            depth_raw1 = o3d.io.read_image(\"RGBD/color/\"+no+\".jpg\")\n",
    "        elif 100<=i<1000:\n",
    "            no = \"000\"+str(i)\n",
    "            color_raw1 = o3d.io.read_image(\"RGBD/color/\"+no+\".jpg\")\n",
    "            depth_raw1 = o3d.io.read_image(\"RGBD/color/\"+no+\".jpg\")\n",
    "        else:\n",
    "            return source\n",
    "        print(no, end=\"... \")\n",
    "\n",
    "        #####################\n",
    "        # Recombine to RGBD #\n",
    "        #####################\n",
    "        rgbd_image1 = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "            color_raw1, \n",
    "            depth_raw1, \n",
    "            convert_rgb_to_intensity = True)\n",
    "\n",
    "        # Create camera model\n",
    "        camera = o3d.camera.PinholeCameraIntrinsic(\n",
    "                o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)\n",
    "\n",
    "        # Target pointcloud\n",
    "        target = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "            rgbd_image1, camera)\n",
    "\n",
    "        # Flip it, otherwise the pointcloud will be upside down\n",
    "        target.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "        ##############\n",
    "        # Downsample #\n",
    "        ##############\n",
    "        # 1 Downsample both point clouds\n",
    "        #source = source.voxel_down_sample(voxel_size=voxel_size)\n",
    "        #target = target.voxel_down_sample(voxel_size=voxel_size)\n",
    "        # 2 Estimate surface normals of pointclouds\n",
    "        source.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                                max_nn=30),fast_normal_computation=True)\n",
    "        target.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                                max_nn=30),fast_normal_computation=True)\n",
    "\n",
    "        #######\n",
    "        # ICP #\n",
    "        #######\n",
    "        # Parameters\n",
    "        threshold = 0.02\n",
    "        trans_init = np.asarray([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "        #point_to_point =  o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "        point_to_plane =  o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "\n",
    "        icp_result = o3d.pipelines.registration.registration_icp(\n",
    "            source,\n",
    "            target,\n",
    "            max_correspondence_distance=threshold,\n",
    "            init=trans_init, \n",
    "            estimation_method=point_to_plane\n",
    "            )\n",
    "        \n",
    "        # Transform the source points to targets coordinates, and add target\n",
    "        source += target.transform(icp_result.transformation) #.voxel_down_sample(voxel_size=voxel_size)\n",
    "    return source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_image0 = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "    color_raw0, \n",
    "    depth_raw0, \n",
    "    convert_rgb_to_intensity = True)\n",
    "    \n",
    "# Create camera model\n",
    "camera = o3d.camera.PinholeCameraIntrinsic(\n",
    "        o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault)\n",
    "\n",
    "# Source pointcloud\n",
    "source = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "    rgbd_image0, camera)\n",
    "\n",
    "# Flip it, otherwise the pointcloud will be upside down\n",
    "source.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "# 1 Downsample both point clouds\n",
    "source = source.voxel_down_sample(voxel_size=voxel_size)\n",
    "# 2 Estimate surface normals of pointclouds\n",
    "source.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=0.5,\n",
    "                            max_nn=30),fast_normal_computation=True)\n",
    "\n",
    "################\n",
    "# Do the stuff #\n",
    "################\n",
    "#for i in range(1, 100):\n",
    "    #source = add_new_pc(copy.deepcopy(source), i, voxel_size=voxel_size)\n",
    "    #if i % 10 == 0:\n",
    "    #    source=source.voxel_down_sample(voxel_size=voxel_size)\n",
    "\n",
    "result = whole_process(copy.deepcopy(source), voxel_size=voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyoints import (\n",
    "    storage,\n",
    "    Extent,\n",
    "    transformation,\n",
    "    filters,\n",
    "    registration,\n",
    "    normals,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Map():\n",
    "    def __init__(self):\n",
    "        self.map = np.array([]) # Pointcloud for map [[x, y], [x, y], ...]\n",
    "\n",
    "    def add_point(self, x, y):\n",
    "        self.map = np.append(self.map, [[x, y]], axis=0) # Add new measurement to map\n",
    "    \n",
    "    def add_pointcloud(self, pointcloud):\n",
    "        '''Takes a pointcloud and run icp to align it with the map and add it to the map\n",
    "        input:\n",
    "        pointcloud: [[x, y], [x, y], ...]\n",
    "        '''\n",
    "        pc = self.run_icp(pointcloud)\n",
    "        self.map = np.append(self.map, pc, axis=0)\n",
    "\n",
    "    def run_icp(self, pointcloud, max_iter, min_delta_err, init_T=np.eye(3)):\n",
    "        '''Run icp to align a pointcloud with the map\n",
    "        input:\n",
    "        pointcloud: [[x, y], [x, y], ...]\n",
    "        '''\n",
    "        # downsample pointcloud\n",
    "        # pointcloud = sklearn.utils.resample(pointcloud, n_samples=100, replace=False, random_state=0)\n",
    "        print(pointcloud.shape)\n",
    "        pointcloud = np.random.choice(pointcloud.shape[0], 100, replace=False)\n",
    "        print(pointcloud.shape)\n",
    "        \n",
    "        point_dict = {\n",
    "            'A': self.map,\n",
    "            'B': pointcloud\n",
    "        }\n",
    "\n",
    "        d_th = 0.04\n",
    "        radii = [d_th, d_th, d_th]\n",
    "        icp = registration.ICP(\n",
    "            radii,\n",
    "            max_iter=60,\n",
    "            max_change_ratio=0.000001,\n",
    "            k=1\n",
    "        )\n",
    "\n",
    "        T_dict, pairs_dict, report = icp(point_dict)\n",
    "        T = T_dict['B']\n",
    "        return T @ pointcloud.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " import cv2\n",
    " import numpy as np\n",
    " import matplotlib.pyplot as plt\n",
    " from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icp(a, b, init_pose=(0,0,0), no_iterations = 100):\n",
    "    '''\n",
    "    The Iterative Closest Point estimator.\n",
    "    Takes two cloudpoints a[x,y], b[x,y], an initial estimation of\n",
    "    their relative pose and the number of iterations\n",
    "    Returns the affine transform that transforms\n",
    "    the cloudpoint a to the cloudpoint b.\n",
    "    Note:\n",
    "        (1) This method works for cloudpoints with minor\n",
    "        transformations. Thus, the result depents greatly on\n",
    "        the initial pose estimation.\n",
    "        (2) A large number of iterations does not necessarily\n",
    "        ensure convergence. Contrarily, most of the time it\n",
    "        produces worse results.\n",
    "    '''\n",
    "\n",
    "    src = np.array([a.T], copy=True).astype(np.float32)\n",
    "    dst = np.array([b.T], copy=True).astype(np.float32)\n",
    "\n",
    "    #Initialise with the initial pose estimation\n",
    "    Tr = np.array([[np.cos(init_pose[2]),-np.sin(init_pose[2]),init_pose[0]],\n",
    "                   [np.sin(init_pose[2]), np.cos(init_pose[2]),init_pose[1]],\n",
    "                   [0,                    0,                   1          ]])\n",
    "\n",
    "    src = cv2.transform(src, Tr[0:2])\n",
    "\n",
    "    for i in range(no_iterations):\n",
    "        #Find the nearest neighbours between the current source and the\n",
    "        #destination cloudpoint\n",
    "        nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto').fit(dst[0])\n",
    "        distances, indices = nbrs.kneighbors(src[0])\n",
    "\n",
    "        #Compute the transformation between the current source\n",
    "        #and destination cloudpoint\n",
    "        T, inliers = cv2.estimateAffine2D(src, dst[0, indices.T]) # retval, inliers\n",
    "        #Transform the previous source and update the\n",
    "        #current source cloudpoint\n",
    "        src = cv2.transform(src, T)\n",
    "        #Save the transformation from the actual source cloudpoint\n",
    "        #to the destination\n",
    "        Tr = np.dot(Tr, np.vstack((T,[0,0,1])))\n",
    "    return Tr[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the datasets\n",
    "ang = np.linspace(-np.pi/2, np.pi/2, 50)\n",
    "a = np.array([ang, np.sin(ang)])\n",
    "th = np.pi/2\n",
    "rot = np.array([[np.cos(th), -np.sin(th)],[np.sin(th), np.cos(th)]])\n",
    "b = np.dot(rot, a) + np.array([[0.2], [0.3]])\n",
    "\n",
    "\n",
    "#Run the icp\n",
    "M2 = icp(b, a, [0.1,  0.33, np.pi/2.2], 100)\n",
    "\n",
    "#Plot the result\n",
    "src = np.array([a.T]).astype(np.float32)\n",
    "res = cv2.transform(src, M2)\n",
    "plt.figure()\n",
    "plt.plot(a[0], a[1], 'b.')\n",
    "plt.plot(b[0],b[1], 'r.')\n",
    "plt.plot(res[0].T[0], res[0].T[1], 'g.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x     y      z  selected\n",
      "0     -3.73 -0.78  12.79      True\n",
      "1     -4.44 -0.58  12.89      True\n",
      "2     -6.45 -4.30  15.12      True\n",
      "3     -0.03 -2.33  13.02      True\n",
      "4     -2.19 -0.91  12.67      True\n",
      "...     ...   ...    ...       ...\n",
      "20697 -4.45 -0.65  14.61      True\n",
      "20698 -5.19 -0.46  14.29      True\n",
      "20699 -4.84 -0.68  14.42      True\n",
      "20700 -5.21 -0.47  14.14      True\n",
      "20701 -5.07 -0.48  14.42      True\n",
      "\n",
      "[20702 rows x 4 columns]\n",
      "Consider partial overlap of point clouds ...\n",
      "Select points for correspondences in fixed point cloud ...\n",
      "Estimate normals of selected points ...\n",
      "Start iterations ...\n",
      "iteration | correspondences | mean(residuals) |  std(residuals)\n",
      "   orig:0 |             863 |          0.0403 |          0.1825\n",
      "        1 |             862 |          0.0096 |          0.1113\n",
      "        2 |             775 |          0.0050 |          0.0553\n",
      "        3 |             807 |          0.0022 |          0.0407\n",
      "        4 |             825 |          0.0016 |          0.0346\n",
      "        5 |             825 |          0.0010 |          0.0253\n",
      "        6 |             816 |          0.0008 |          0.0198\n",
      "        7 |             785 |         -0.0000 |          0.0142\n",
      "        8 |             764 |          0.0008 |          0.0091\n",
      "        9 |             753 |          0.0003 |          0.0061\n",
      "       10 |             735 |          0.0002 |          0.0040\n",
      "       11 |             742 |         -0.0001 |          0.0032\n",
      "       12 |             747 |         -0.0000 |          0.0030\n",
      "       13 |             752 |         -0.0000 |          0.0030\n",
      "       14 |             752 |         -0.0000 |          0.0029\n",
      "Convergence criteria fulfilled -> stop iteration!\n",
      "Estimated transformation matrix H:\n",
      "[    0.984798    -0.173702    -0.000053     0.000676]\n",
      "[    0.173702     0.984798     0.000084    -0.001150]\n",
      "[    0.000038    -0.000092     1.000000     0.000113]\n",
      "[    0.000000     0.000000     0.000000     1.000000]\n",
      "... which corresponds to the following rigid-body transformation parameters:\n",
      "parameter |       est.value | est.uncertainty |       obs.value |      obs.weight\n",
      "   alpha1 |       -0.004804 |        0.004491 |        0.000000 |       0.000e+00\n",
      "   alpha2 |       -0.003061 |        0.002104 |        0.000000 |       0.000e+00\n",
      "   alpha3 |       10.003124 |        0.005680 |        0.000000 |       0.000e+00\n",
      "       tx |        0.000676 |        0.000418 |        0.000000 |       0.000e+00\n",
      "       ty |       -0.001150 |        0.000885 |        0.000000 |       0.000e+00\n",
      "       tz |        0.000113 |        0.000189 |        0.000000 |       0.000e+00\n",
      "(Unit of est.value, est.uncertainty, and obs.value for alpha1/2/3 is degree)\n",
      "Finished in 19.452 seconds!\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from simpleicp import PointCloud, SimpleICP\n",
    "import numpy as np\n",
    "\n",
    "# Read point clouds from xyz files into n-by-3 numpy arrays\n",
    "X_fix = np.genfromtxt(\"bunny_part1.xyz\")\n",
    "X_mov = np.genfromtxt(\"bunny_part2.xyz\")\n",
    "\n",
    "\n",
    "# X_fix = np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 1]])\n",
    "# X_mov = X_fix + 0.1\n",
    "\n",
    "\n",
    "# print(X_fix.shape)\n",
    "\n",
    "\n",
    "# Create point cloud objects\n",
    "pc_fix = PointCloud(X_fix, columns=[\"x\", \"y\", \"z\"])\n",
    "pc_mov = PointCloud(X_mov, columns=[\"x\", \"y\", \"z\"])\n",
    "# plt.plot(X_fix[:, 0], X_fix[:, 1], 'b.')\n",
    "# plt.plot(X_mov[:, 0], X_mov[:, 1], 'r.')\n",
    "# plt.show()\n",
    "\n",
    "print(pc_fix)\n",
    "# Create simpleICP object, add point clouds, and run algorithm!\n",
    "icp = SimpleICP()\n",
    "icp.add_point_clouds(pc_fix, pc_mov)\n",
    "H, X_mov_transformed, rigid_body_transformation_params = icp.run(max_overlap_distance=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
